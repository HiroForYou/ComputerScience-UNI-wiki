{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examen Final de Inteligencia Artificial \n",
    "\n",
    "Esta es la primera parte del examen final de Inteligencia Artificial que abarca aspectos teóricos del curso.\n",
    "\n",
    "* Tienes 120 minutos como máximo para responder tantas preguntas como sea posible. No se ́admiten examenes fuera de tiempo. ́\n",
    "\n",
    "* Escribe en este cuaderno todas tus respuestas. No se admiten otros tipos de archivos.\n",
    "\n",
    "* Si  no  cuentas  con  una  herramienta  para  dibujar  tablas  o  alguna  otra  cosa  solicitada  en  la prueba,  puedes  presentar  imagenes  hechas  a  mano  que  justifiquen  tus  respuestas. Es tu responsabilidad si se pueden ver o leer.  No se admiten figuras como respuesta. \n",
    "\n",
    "* No se admiten copias. Cualquier evidencia de copia de otra fuente no serán consideradas y el puntaje será cero. Si la copia implica varias preguntas (por lo menos dos) se anulará el examen con OA. \n",
    "\n",
    "* Responder las preguntas en orden.\n",
    "\n",
    "* **Solo se puntua si se han respondido todos las ítem de las preguntas, no se tomará en cuenta las preguntas incompletas**.\n",
    "\n",
    "* Escribe tus respuestas lo mas precisas posible, utilizando todos los conceptos aprendidos en ́clase. \n",
    "\n",
    "\n",
    "#### Nombre y Apellidos: Sánchez Sauñe Cristhian Wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Imagina que eres un sistema de visión. Cuando te enciendes por primera vez, una imagen inunda tu cámara. Puedes ver muchas cosas, pero no todas. No puedes ver los objetos que están ocluidos y por supuesto, no puedes ver los objetos que están detrás. Después de ver esa primera escena, ¿tienes acceso al estado del entorno de Markov? Supongamos que tu cámara se rompió ese día y no recibistes ninguna imagen en todo el día. ¿Entonces tendrías acceso al estado de Markov? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La información que tengo simplemente no es suficiente para predecir el futuro. Después de ver esa primera escena, no tengo acceso al entorno del estado de Markov. No puedo ver los objetos detrás de mí. El objeto detrás de mí, digamos, un automóvil que está a punto de chocar con los objetos frente a mí, puede tener un impacto en la escena que vería en el futuro inmediato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ¿Cuáles de las siguientes afirmaciones se aplican a las redes neuronales convolucionales (CNN) para el análisis de imágenes?\n",
    "\n",
    "    - Los filtros en capas anteriores tienden a incluir detectores de bordes\n",
    "\n",
    "    - El pooling  de capas reduce la resolución espacial de la imagen\n",
    "\n",
    "    - Tienen más parámetros que las redes completamente conectadas con el mismo número de capas y el mismo número de neuronas en cada capa.\n",
    "\n",
    "    - Una CNN se puede entrenar para tareas de aprendizaje sin supervisión, mientras que una red neuronal ordinaria no puede. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tus respuestas\n",
    "\n",
    "* Verdadero : Las capas inferiores captan características de bajo nivel como bordes o texturas; mientras que las capas superiores características más complejas.\n",
    "\n",
    "* Verdadero: Se usa pooling para reducir el número de parámetros a procesar por la CNN, rescatando aquellas características más importantes o que representan mejor la información de una zona de la imagen (mediante Max Pooling o Average Pooling)\n",
    "\n",
    "* Falso: Tienes menos parámetros entrenables, por ello que se usa para procesar las imágenes. Lo parámetros entrenables se reduce a la cantidad de filtros kernel de la red.\n",
    "\n",
    "* Falso: Si se puede usar ambas redes para ese tipo de tareas, solo que el enfoque de entrenamiento varía. Un ejemplo son los VAE's, que aveces se componen de capas convoluciones y capas densas, y son entrenadas mediante un enfoque no supervisado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Quieres entrenar una red neuronal para conducir un automóvil. Tus datos de entrenamiento constan de imágenes en escala de grises de $64 \\times 64$ píxeles. Las etiquetas de entrenamiento incluyen el ángulo del volante del conductor en grados y la velocidad del conductor en millas por hora. Tu red neuronal consta de una capa de entrada con $64 \\times 64 = 4096$ unidades, una capa oculta con $2048$ unidades y una capa de salida con $2$ unidades (una para el ángulo de dirección y otra para la velocidad). Utiliza la función de activación ReLU para las unidades ocultas y ninguna función de activación para las salidas (o entradas).\n",
    "\n",
    "    - Calcula el número de parámetros (pesos) en esta red. Puedes dejar tu respuesta como expresión. Asegúrate de tener en cuenta los términos de sesgo. \n",
    "    \n",
    "    - Entrena tu red con la función de costo $J = \\frac{1}{2}\\vert \\mathbf{y} - \\mathbf{z}\\vert ^2$. Utiliza la siguiente notación.\n",
    "    \n",
    "        - $\\mathbf{x}$ es un vector de imagen de entrenamiento (entrada) con un componente 1 agregado al final, $\\mathbf{y}$ es un vector de etiqueta de entrenamiento (entrada) y $\\mathbf{z}$ es el vector de salida. Todos los vectores son vectores columna.\n",
    "        - $r(\\gamma) = max\\{0, \\gamma\\}$ es la función de activación de ReLU, $r^{'}(\\gamma)$ es su derivada y $r (\\mathbf{v})$ es $r(\\cdot)$  aplicado a los componente de un vector.\n",
    "        - $\\mathbf{g}$ es el vector de valores unitarios ocultos antes de que se aplique las función de activación  ReLU, y $\\mathbf{h} = r (\\mathbf{g})$ es el vector de valores unitarios ocultos después de su aplicación (pero agregamos un componente 1 al final de $\\mathbf{h}$).\n",
    "\n",
    "        - V es la matriz de ponderaciones que asigna la capa de entrada a la capa oculta,  $\\mathbf{g} = V\\mathbf{x}$.\n",
    "\n",
    "        - W es la matriz de peso que asigna la capa oculta a la capa de salida,  $\\mathbf{z} = W\\mathbf{h}$. \n",
    "        \n",
    "     Calcula $\\partial J/\\partial W_{i,j}$ así como $\\partial J/\\partial V_{i,j}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\partial J/\\partial W_{i,j}$:\n",
    "\n",
    "$J = \\frac{1}{2}\\vert \\mathbf{y} - \\mathbf{z}\\vert ^2$\n",
    "\n",
    "tomaremos los 2 casos para el valor absoluto:\n",
    "\n",
    "$\\frac{\\partial J}{\\partial W} = - (y - W \\cdot h)h$  si y-z es $\\geq 0$\n",
    "\n",
    "$\\frac{\\partial J}{\\partial W} = (y - W \\cdot h)h$  caso contrario\n",
    "\n",
    "\n",
    "- $\\partial J/\\partial V_{i,j}$:\n",
    "\n",
    "$J = \\frac{1}{2}\\vert \\mathbf{y} - \\mathbf{z}\\vert ^2$\n",
    "\n",
    "tomaremos los 2 casos para el valor absoluto:\n",
    "\n",
    "$\\frac{\\partial J}{\\partial V} = - (y - W \\cdot h) \\frac{\\partial (W \\cdot r(VX))}{\\partial V}$\n",
    "\n",
    "$\\frac{\\partial J}{\\partial V} = - (y - W \\cdot h) \\frac{\\partial (W \\cdot max(VX, 0))}{\\partial V}$\n",
    "\n",
    "$\\frac{\\partial J}{\\partial V} = - (y - W \\cdot h) \\frac{\\partial (W \\cdot X max(V, 0))}{\\partial V}$\n",
    "\n",
    "$\\frac{\\partial J}{\\partial V} = - (y - W \\cdot h) WX \\frac{\\partial max(V, 0)}{\\partial V}$\n",
    "\n",
    "$\\frac{\\partial J}{\\partial V} = - (y - W \\cdot h) WX r'(V)$ si y-z es $\\geq 0$\n",
    "\n",
    "$\\frac{\\partial J}{\\partial V} = (y - W \\cdot h) WX r'(V)$ caso contrario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Observas a un agente A1 jugando Pacman. ¿Cómo puedes utilizar los movimientos que observa para entrenar a tu propio agente?\n",
    "\n",
    "    - Describe formalmente los datos que recolectarías, el problema de inferencia que considerarías y cómo lo resolvería.\n",
    "\n",
    "    - ¿Cómo diseñarías una red neuronal para controlar a tu agente? Define matemáticamente la arquitectura de la red neuronal, sus entradas, sus salidas, sus parámetros, así como la pérdida que usaría para entrenarla.\n",
    "\n",
    "    - Discute el rendimiento esperado del agente resultante cuando (a) el agente A1 es óptimo y (b) el agente A1 es subóptimo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Recolectaría los datos donde se encuentran las recompensas, donde se encuentran los enemigos, y donde se encuentran los obstaculos. Un subproducto (o posibles combinaciones) de estas muestras serán usadas por la red neuronal.\n",
    "\n",
    "* Las entradas pueden ser: 4 distancias a las paredes (frente, atras, derecha, izquierda), 4 distancias a la recompensa (frente, atras, derecha, izquierda), 4 distancias a los enemigos (frente, atras, derecha, izquierda). Y la salida puede ser la dirección que tomará el siguiente movimiento del agente. Las capas ocultas por lo estándar, deberían tenerse a lo mucho 2 capas, de 8 neuronas cada una, con función de activación ReLu para agilizar los cálculos. La función de pérdida (al tratarse de un problema de RL), podría basarse en una política diferenciable $\\Pi$. Los parámetros a optimizar dentro de la red neuronal serán justamente los parámetros entrenables $\\theta$ pertenecientes a la política $\\Pi~$. Aquí cabe mencionar, que hay muchos algoritmos en RL que permiten encontrar los valores óptimos para la política, a continuación detallaré el algoritmo **REINFORCE**:\n",
    "\n",
    "\n",
    "![](https://i.stack.imgur.com/c6pud.png)\n",
    "\n",
    "\n",
    "* Cuando el agente es óptimo, puede encontrar las soluciones en un corto tiempo, y con la recompensa máxima posible. En cambio en un agente subóptimo, obtendríamos soluciones en un tiempo prolongado (e incluso nunca) y una recompensa greedy que no es la máximo posible. En el primer caso, el agente logra generalizar los movimientos posibles que lo llevarán más fácilmente a la recompensa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Pacbaby ha notado que en la década de 1970, casi todos los que usan gafas de sol también tienen bigote, ya sea que la persona en cuestión sea Pacman, un fantasma o incluso una joven Pacman. Entonces Pacbaby decide que es hora de una actualización de su cerebro naive Bayes: está obteniendo un cerebro naive Bayes aumentado con árboles para que las características que observa no tengan que ser independientes.\n",
    "\n",
    "    En esta pregunta, exploraremos el aprendizaje y la inferencia en una abstracción del nuevo cerebro de Pacbaby. Un modelo TAN es idéntico a un modelo Naive Bayes, excepto que las características ya no se asumen condicionalmente independientes dada la clase $Y$. Específicamente, si $(X_1, X_2, \\dots, X_n)$ son las variables que representan las características que Pacbaby puede observar, un TAN permite $X_1, \\dots, X_n$ para estar en una red Bayesiana estructurada en árbol además de tener $Y$ como padre. El ejemplo que exploramos está en el siguiente gráfico:\n",
    "\n",
    "![](TAN.png)\n",
    "\n",
    "- Supongamos que no observamos variables como evidencia en el TAN anterior. ¿Cuál es la regla de clasificación del TAN? Escribe la fórmula en términos de las CPT y probabilidades previas en el TAN.\n",
    "\n",
    "- Supongamos que observamos todas las variables $X_1 = x_1, X_2 = x_2, \\dots X_6 = x_6$ en el TAN anterior. ¿Cuál es la regla de clasificación del TAN? Escribe la fórmula en términos de los CPT y las probabilidades previas en el TAN.\n",
    "\n",
    "- Especifica un orden de eliminación que sea eficiente para la consulta $P(Y| X_5 = x_5)$ en el TAN anterior (incluye $Y$ en tu orden). ¿Cuántas variables hay en el factor más grande  inducidas por la eliminación de variables con el orden? ¿Qué variables son?.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
