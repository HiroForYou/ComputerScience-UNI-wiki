{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYE-JU8vC9uh"
      },
      "source": [
        "### Un perceptrón básico en pytorch\n",
        "\n",
        "Ecribamos la codificación de la red neuronal más simple posible:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4Lixdv6DJ3_"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJpsQYBnD6yv"
      },
      "source": [
        "Definimos una red con una sola neurona."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP039f4OD42u"
      },
      "source": [
        "class Red(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Red,self).__init__()\n",
        "    self.fc1 = nn.Linear(1,1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUI3-J_oEgAu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "225e429b-7e67-457a-a678-8855b9ab0374"
      },
      "source": [
        "red = Red()\n",
        "print(red)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Red(\n",
            "  (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSXMN0S4F-NC"
      },
      "source": [
        "Entonces es posible echar un vistazo a los parámetros de la red. Los parámetros son optimizados automáticamente por la red. Los hiperparámetros, como la velocidad de aprendizaje, requieren el ajuste por parte de un humano (hasta ahora, al menos)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T90SdMtgFpJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fbebd09-c570-4034-e4e7-b63c3227d4e3"
      },
      "source": [
        "print(list(red.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[-0.5807]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.9690], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5GJgx7qGqG1"
      },
      "source": [
        "Trabajemos con esta red neuronal básica."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRgCMkD4GKZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "157ec285-82dd-4139-a173-b1660cdad3c6"
      },
      "source": [
        "entrada = Variable(torch.randn(1,1,1), requires_grad=True)\n",
        "print(entrada)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[1.9279]]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWABEzL7HSxF"
      },
      "source": [
        "Sí, acabamos de crear un número aleatorio con PyTorch. Es un tensor con una sola dimensión (alternativamente, `torch.FloatTensor([[[1]]])` crearía un tensor equivalente con el valor `1`). **Establecer `require_grad` significa que es una variable optimizable. Entonces puedes lanzar este número a través de la red no aprendida**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P3dFadkHBI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd8f0114-622a-4d42-a85e-d3bb7d6cdb11"
      },
      "source": [
        "salida = red(entrada)\n",
        "print(salida)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[-2.0886]]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D0m715TH2ja"
      },
      "source": [
        "### Función de pérdida y Optimizador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg-fnTjSHnYb"
      },
      "source": [
        "import torch.optim as optim\n",
        "def criterio(salida, etiqueta):\n",
        "  return (etiqueta -salida)** 2\n",
        "\n",
        "optimizador = optim.SGD(red.parameters(), lr=0.01, momentum = 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ng6gqkDJnrC"
      },
      "source": [
        "Definamos ahora un conjunto de datos de entrenamiento. Para este caso  solo vamos a enseñar a la red cómo triplicar un número: nuestro objetivo para el  perceptrón  Ax + b será que A = 3 y b = 0. Un conjunto de datos de entrenamiento simple es:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzyZnoPEIfSD"
      },
      "source": [
        "datos = [(1,3), (2,6), (3,9), (4,12), (5,15), (6,18)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKGaInWYKA9m"
      },
      "source": [
        "Entonces, el bucle de entrenamiento se ve como:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntaS5YKkJ-ry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a81916c-af1e-4ab1-b8d5-1b2e77f232ed"
      },
      "source": [
        "for epoch in range(100):\n",
        "  for i, datos1 in enumerate(datos):\n",
        "    X,Y =iter(datos1)\n",
        "    X,Y = Variable(torch.FloatTensor([X]), requires_grad =True), Variable(torch.FloatTensor([Y]),\n",
        "                                                                        requires_grad=False)\n",
        "    \n",
        "    optimizador.zero_grad()\n",
        "    salidas = red(X)\n",
        "    f_perdida =criterio(salidas, Y)\n",
        "    f_perdida.backward()\n",
        "    optimizador.step()\n",
        "    if (i% 10 == 0):\n",
        "      print(\"Epoca {}-FuncionPerdida: {}\".format(epoch, f_perdida.data[0]))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoca 0-FuncionPerdida: 20.6999454498291\n",
            "Epoca 1-FuncionPerdida: 0.9244413375854492\n",
            "Epoca 2-FuncionPerdida: 0.006411971524357796\n",
            "Epoca 3-FuncionPerdida: 0.056640781462192535\n",
            "Epoca 4-FuncionPerdida: 0.013704035431146622\n",
            "Epoca 5-FuncionPerdida: 0.022266890853643417\n",
            "Epoca 6-FuncionPerdida: 0.01642902009189129\n",
            "Epoca 7-FuncionPerdida: 0.01595809869468212\n",
            "Epoca 8-FuncionPerdida: 0.013971650041639805\n",
            "Epoca 9-FuncionPerdida: 0.012708649970591068\n",
            "Epoca 10-FuncionPerdida: 0.011396888643503189\n",
            "Epoca 11-FuncionPerdida: 0.010274446569383144\n",
            "Epoca 12-FuncionPerdida: 0.00924444105476141\n",
            "Epoca 13-FuncionPerdida: 0.008323724381625652\n",
            "Epoca 14-FuncionPerdida: 0.0074927592650055885\n",
            "Epoca 15-FuncionPerdida: 0.006745329592376947\n",
            "Epoca 16-FuncionPerdida: 0.006072300486266613\n",
            "Epoca 17-FuncionPerdida: 0.005466494709253311\n",
            "Epoca 18-FuncionPerdida: 0.004921008367091417\n",
            "Epoca 19-FuncionPerdida: 0.004430110566318035\n",
            "Epoca 20-FuncionPerdida: 0.003988094162195921\n",
            "Epoca 21-FuncionPerdida: 0.0035902149975299835\n",
            "Epoca 22-FuncionPerdida: 0.0032319987658411264\n",
            "Epoca 23-FuncionPerdida: 0.0029095555655658245\n",
            "Epoca 24-FuncionPerdida: 0.0026192343793809414\n",
            "Epoca 25-FuncionPerdida: 0.0023579252883791924\n",
            "Epoca 26-FuncionPerdida: 0.00212267367169261\n",
            "Epoca 27-FuncionPerdida: 0.001910876133479178\n",
            "Epoca 28-FuncionPerdida: 0.001720219966955483\n",
            "Epoca 29-FuncionPerdida: 0.0015486127231270075\n",
            "Epoca 30-FuncionPerdida: 0.0013940919889137149\n",
            "Epoca 31-FuncionPerdida: 0.001254977541975677\n",
            "Epoca 32-FuncionPerdida: 0.0011297994060441852\n",
            "Epoca 33-FuncionPerdida: 0.001017073169350624\n",
            "Epoca 34-FuncionPerdida: 0.000915600685402751\n",
            "Epoca 35-FuncionPerdida: 0.0008242166368290782\n",
            "Epoca 36-FuncionPerdida: 0.0007419936591759324\n",
            "Epoca 37-FuncionPerdida: 0.000667941989377141\n",
            "Epoca 38-FuncionPerdida: 0.0006013083620928228\n",
            "Epoca 39-FuncionPerdida: 0.0005413214094005525\n",
            "Epoca 40-FuncionPerdida: 0.000487302866531536\n",
            "Epoca 41-FuncionPerdida: 0.0004387160297483206\n",
            "Epoca 42-FuncionPerdida: 0.00039492282667197287\n",
            "Epoca 43-FuncionPerdida: 0.0003555325965862721\n",
            "Epoca 44-FuncionPerdida: 0.00032004271633923054\n",
            "Epoca 45-FuncionPerdida: 0.00028812381788156927\n",
            "Epoca 46-FuncionPerdida: 0.00025936131714843214\n",
            "Epoca 47-FuncionPerdida: 0.00023350051196757704\n",
            "Epoca 48-FuncionPerdida: 0.00021019877749495208\n",
            "Epoca 49-FuncionPerdida: 0.00018922198796644807\n",
            "Epoca 50-FuncionPerdida: 0.00017034813936334103\n",
            "Epoca 51-FuncionPerdida: 0.00015335601347032934\n",
            "Epoca 52-FuncionPerdida: 0.00013805089110974222\n",
            "Epoca 53-FuncionPerdida: 0.0001242826838279143\n",
            "Epoca 54-FuncionPerdida: 0.00011188224016223103\n",
            "Epoca 55-FuncionPerdida: 0.0001007115570246242\n",
            "Epoca 56-FuncionPerdida: 9.067228529602289e-05\n",
            "Epoca 57-FuncionPerdida: 8.162029553204775e-05\n",
            "Epoca 58-FuncionPerdida: 7.348501094384119e-05\n",
            "Epoca 59-FuncionPerdida: 6.614462472498417e-05\n",
            "Epoca 60-FuncionPerdida: 5.9550457081058994e-05\n",
            "Epoca 61-FuncionPerdida: 5.3609262977261096e-05\n",
            "Epoca 62-FuncionPerdida: 4.826137228519656e-05\n",
            "Epoca 63-FuncionPerdida: 4.344549961388111e-05\n",
            "Epoca 64-FuncionPerdida: 3.910900704795495e-05\n",
            "Epoca 65-FuncionPerdida: 3.520669633871876e-05\n",
            "Epoca 66-FuncionPerdida: 3.169439878547564e-05\n",
            "Epoca 67-FuncionPerdida: 2.8537035177578218e-05\n",
            "Epoca 68-FuncionPerdida: 2.5685270884423517e-05\n",
            "Epoca 69-FuncionPerdida: 2.3123253413359635e-05\n",
            "Epoca 70-FuncionPerdida: 2.081746788462624e-05\n",
            "Epoca 71-FuncionPerdida: 1.8739947336143814e-05\n",
            "Epoca 72-FuncionPerdida: 1.687135227257386e-05\n",
            "Epoca 73-FuncionPerdida: 1.5186232303676661e-05\n",
            "Epoca 74-FuncionPerdida: 1.367249569739215e-05\n",
            "Epoca 75-FuncionPerdida: 1.2305029486014973e-05\n",
            "Epoca 76-FuncionPerdida: 1.1079323485319037e-05\n",
            "Epoca 77-FuncionPerdida: 9.975054126698524e-06\n",
            "Epoca 78-FuncionPerdida: 8.977252036856953e-06\n",
            "Epoca 79-FuncionPerdida: 8.083454304141924e-06\n",
            "Epoca 80-FuncionPerdida: 7.276332326000556e-06\n",
            "Epoca 81-FuncionPerdida: 6.5506483224453405e-06\n",
            "Epoca 82-FuncionPerdida: 5.8966079450328834e-06\n",
            "Epoca 83-FuncionPerdida: 5.309870175551623e-06\n",
            "Epoca 84-FuncionPerdida: 4.778858055942692e-06\n",
            "Epoca 85-FuncionPerdida: 4.302478373574559e-06\n",
            "Epoca 86-FuncionPerdida: 3.872657543979585e-06\n",
            "Epoca 87-FuncionPerdida: 3.4867880458477885e-06\n",
            "Epoca 88-FuncionPerdida: 3.1380352538690204e-06\n",
            "Epoca 89-FuncionPerdida: 2.8252600259293104e-06\n",
            "Epoca 90-FuncionPerdida: 2.543329173931852e-06\n",
            "Epoca 91-FuncionPerdida: 2.289182020831504e-06\n",
            "Epoca 92-FuncionPerdida: 2.0613972537830705e-06\n",
            "Epoca 93-FuncionPerdida: 1.8565756363386754e-06\n",
            "Epoca 94-FuncionPerdida: 1.6704711924830917e-06\n",
            "Epoca 95-FuncionPerdida: 1.5035338947200216e-06\n",
            "Epoca 96-FuncionPerdida: 1.3536919141188264e-06\n",
            "Epoca 97-FuncionPerdida: 1.2190730558359064e-06\n",
            "Epoca 98-FuncionPerdida: 1.0974893029924715e-06\n",
            "Epoca 99-FuncionPerdida: 9.879704521154054e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpbCksmdMkz5"
      },
      "source": [
        "¿Llegamos a Ax + b (3x + 0)? Casi:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRV8zLiDLil0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913b1919-b296-403e-f009-e30552e1a8e4"
      },
      "source": [
        "print(list(red.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[2.9998]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0011], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uarag6chMtvl"
      },
      "source": [
        "¿Qué hay acerca de las predicciones?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKI-IHTjMqhv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5cb476e-25bb-4d07-d169-5bedfcaadf89"
      },
      "source": [
        "print(red(Variable(torch.Tensor([[[1]]]))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[3.0009]]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTqs8nJYN7eZ"
      },
      "source": [
        "### Multilayer Perceptron\n",
        "\n",
        "El mismo código  todavía funciona para una red de dos capas (o más que eso). Solo cambia la forma en que se construye la red. Tenga en cuenta que las capas deben coincidir en términos de cantidad de salidas de una capa y de entradas a la siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5Y5p4yjM9sR"
      },
      "source": [
        "class Red(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Red, self).__init__()\n",
        "    self.fc1 = nn.Linear(1, 10)\n",
        "    self.fc2 = nn.Linear(10,1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.fc2(self.fc1(x))\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roGJOCB2PP4r"
      },
      "source": [
        " ### GPU\n",
        "\n",
        "Es notablemente fácil con PyTorch pasar la computación a la GPU, asumiendo que puede permitirse uno en estos tiempos de escasez de DDR y minería criptográfica. Simplemente desplace la red y las variables a la GPU con `cuda()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvLIo0RiPBnG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdc6792d-b40a-4a51-f31f-58df189e3e77"
      },
      "source": [
        "red = Red()\n",
        "red.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Red(\n",
              "  (fc1): Linear(in_features=1, out_features=10, bias=True)\n",
              "  (fc2): Linear(in_features=10, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43SKD8ZWQaz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3184942-8a44-4350-8f89-1e01def32dc3"
      },
      "source": [
        "print(list(red.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 0.0852],\n",
            "        [ 0.8926],\n",
            "        [-0.4824],\n",
            "        [ 0.8563],\n",
            "        [ 0.2060],\n",
            "        [-0.8734],\n",
            "        [-0.5102],\n",
            "        [ 0.5776],\n",
            "        [ 0.5295],\n",
            "        [ 0.3026]], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([ 0.6319,  0.5182,  0.0059,  0.4588, -0.4930, -0.0521, -0.2336,  0.6435,\n",
            "         0.3214, -0.3157], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([[-0.1780, -0.1619,  0.1026,  0.2500,  0.1539,  0.2664,  0.1547, -0.1572,\n",
            "         -0.0159,  0.2245]], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([0.1121], device='cuda:0', requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-7QwA2iQhPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "123e90d6-5b2a-4ba6-e4b1-2f467d69b71a"
      },
      "source": [
        "entrada =Variable(torch.randn(1,1,1)).cuda()\n",
        "print (entrada)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[3.1484]]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Kwr__eHRRkH"
      },
      "source": [
        "Las redes neuronales solo funcionan porque cada neurona tiene cierta no linealidad. Lo que sorprende a mi mente como alguien que creció con sigmoide y tanh, es que el mejor tipo de no linealidad en estos días es ReLU, o Unidad Lineal Rectificada. Es decir, si la suma de la neurona es negativa, establézcase en cero, de lo contrario proceda como de costumbre.\n",
        "\n",
        "Con gusto puedes reconstruir la red con ReLU y se entrenará de la misma manera."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQn4CCvvQq02"
      },
      "source": [
        "red.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36zOEr44RcVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6d07050-35e9-4311-9593-b4847cc338f1"
      },
      "source": [
        "salida = red(entrada)\n",
        "print(salida)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[-1.2362]]], device='cuda:0', grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwLsq94zRgp_"
      },
      "source": [
        "import torch.optim as optim\n",
        "optimizador = optim.SGD(red.parameters(), lr = 0.001, momentum=0.4)\n",
        "criterio = nn.MSELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho8loMxfR9lb"
      },
      "source": [
        "datos =[(1,3), (2, 6), (3, 9), (4, 12), (5, 15), (6, 18), (7, 21), (8, 24), (9, 27), (10, 30)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61Gsn_NjSU-Q"
      },
      "source": [
        "El bucle de entrenamiento para este caso es:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls1y-O_lSbeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f39ba75-1129-48c1-c96e-8e0c195a2599"
      },
      "source": [
        "for epoch in range(100):\n",
        "  for i, datos1 in enumerate(datos):\n",
        "    X, Y =iter(datos1)\n",
        "    X, Y = Variable(torch.FloatTensor([X]), requires_grad=True).cuda(), Variable(torch.FloatTensor([Y]), requires_grad=False).cuda()\n",
        "      \n",
        "    optimizador.zero_grad()\n",
        "    y_pred = red(X)\n",
        "    salida = criterio(y_pred,Y)\n",
        "    salida.backward()\n",
        "    optimizador.step()\n",
        "  \n",
        "  if (epoch %20 == 0.0):\n",
        "      print(\"Epoca {} - Funcion_perdida: {}\".format(epoch, salida))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoca 0 - Funcion_perdida: 0.09425553679466248\n",
            "Epoca 20 - Funcion_perdida: 0.0016533053712919354\n",
            "Epoca 40 - Funcion_perdida: 0.0005907497252337635\n",
            "Epoca 60 - Funcion_perdida: 0.00021156984439585358\n",
            "Epoca 80 - Funcion_perdida: 7.597882358822972e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y1j58ogUBlX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77d83701-1022-4ac4-c8bb-464cda3dd9ac"
      },
      "source": [
        "print(list(red.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[-0.0085],\n",
            "        [ 0.9520],\n",
            "        [-0.4881],\n",
            "        [ 1.2326],\n",
            "        [ 0.3403],\n",
            "        [-0.8229],\n",
            "        [-0.4917],\n",
            "        [ 0.5901],\n",
            "        [ 0.6290],\n",
            "        [ 0.5193]], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([ 0.6375,  0.3782,  0.0785,  0.2714, -0.5480,  0.0689, -0.1620,  0.5586,\n",
            "         0.2278, -0.3978], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([[-0.1934,  0.4902, -0.2707,  0.9529,  0.3899, -0.3894, -0.2118,  0.2298,\n",
            "          0.3845,  0.5371]], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([0.0219], device='cuda:0', requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-eWp2pcW3ej"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}