{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica Calificada de Inteligencia Artificial\n",
    "\n",
    "Nombre y apellidos: Sánchez Sauñe Cristhian Wiki\n",
    "\n",
    "#### Indicaciones:\n",
    "\n",
    "* Entregar en este cuaderno todas tus respuestas teoricas. No se aceptan otro tipo de formato.\n",
    "* En esta tarea hay  programas de codificación. Debes presentar pruebas de tus soluciones como el correcto funcionamiento con distintos ejemplos.\n",
    "* Debes responder todas los ítems de las preguntas.\n",
    "* Todo acto de COPIA implica la nota de $0A$. Evita copiar de páginas web!.\n",
    "\n",
    "* Todas las lecturas dadas serán tomadas en cuenta en esta evaluación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lista de ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Traduzca la siguiente expresión lógica de descripción a lógica de primer orden y explica el resultado:\n",
    "\n",
    "```\n",
    "And(Man, AtLeast (3, Son), AtMost(2, Daughter ),\n",
    "    All(Son, And(Unemployed , Married , All(Spouse, Doctor ))),\n",
    "    All(Daughter , And(Professor , Fills(Department , Physics, Math)))).\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu solución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Ejecuta el descenso de gradiente para minimizar la función:\n",
    "\n",
    "$$g(w) = \\frac{1}{50}(w^4 + w^2 +10w)$$\n",
    "\n",
    "con un punto inicial $w_0 = 2$ y $1000$ iteraciones. Haga tres corridas separadas usando cada uno de los valores del tamaño de paso $\\lambda = 1$, $\\lambda = 10^{-1}$ y $\\lambda = 10^{-2}$. Calcula la derivada de esta función a mano e implementa esto (así como la función ) en Python usando NumPy.\n",
    "\n",
    "Traza la gráfica del historial de la función de costo resultante de cada ejecución en una sola figura para comparar su desempeño. ¿Qué valor del tamaño de paso funciona mejor para esta función y punto inicial en particular?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu solucion\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import decimal\n",
    "decimal.getcontext().prec = 100\n",
    "\n",
    "\n",
    "# Debemos diseñar la regla de actualización y las derivadas necesarias\n",
    "\n",
    "g = lambda X: (X**4 + X**2 + 10*X)/50.0\n",
    "d_g = lambda X: (4*(X**3) + 2*X + 10)/50.0   # igualando a 0, tenemos que el mínimo vale -0.16996928431321037, para w=-1.2348\n",
    "cost = lambda X: 0.5*((-0.16996928431321037 - g(X))**2)\n",
    "d_cost = lambda X: -(-0.16996928431321037 - g(X))*d_g(X)\n",
    "\n",
    "class MinFunction:\n",
    "    def __init__(self, lambda_param, g_function=g, d_g_function=d_g, cost_function=cost, d_cost=d_cost, w_0=2.0):\n",
    "        self.lambda_param = lambda_param\n",
    "        self.g_function = g_function\n",
    "        self.d_g_function = d_g_function\n",
    "        self.cost_function = cost_function\n",
    "        self.d_cost = d_cost\n",
    "        self.w = w_0\n",
    "        \n",
    "    def fit(self):\n",
    "        cost_hist = {}\n",
    "        for i in range(1, 1001): \n",
    "            #print(self.w)\n",
    "            self.w -= self.lambda_param*self.d_cost(self.w)\n",
    "            np.round(self.w, 4)\n",
    "            if i%50 == 0:\n",
    "                print(\"G({}) : {} \".format(round(self.w, 4), round(self.g_function(self.w), 4)), end=\"\\t\")\n",
    "                print(\"G'({}) : {} \".format(round(self.w, 4), round(self.d_g_function(self.w), 4)), end=\"\\t\")\n",
    "                print(\"Cost({}) : {} \".format(round(self.w, 4), round(self.cost_function(self.g_function(self.w)), 4)), end=\"\\n\")\n",
    "                cost_hist[i] = self.cost_function(self.g_function(self.w))\n",
    "        return cost_hist\n",
    "    \n",
    "    def predict(self):\n",
    "        return self.g_function(self.w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mostrando resultados para lambda 1 \n",
      "\n",
      "G(-0.6072) : -0.1114 \tG'(-0.6072) : 0.1578 \tCost(-0.6072) : 0.0109 \n",
      "G(-0.8611) : -0.1464 \tG'(-0.8611) : 0.1145 \tCost(-0.8611) : 0.01 \n",
      "G(-0.9546) : -0.1561 \tG'(-0.9546) : 0.0922 \tCost(-0.9546) : 0.0097 \n",
      "G(-1.0041) : -0.1603 \tG'(-1.0041) : 0.0789 \tCost(-1.0041) : 0.0096 \n",
      "G(-1.0353) : -0.1626 \tG'(-1.0353) : 0.0698 \tCost(-1.0353) : 0.0095 \n",
      "G(-1.0571) : -0.1641 \tG'(-1.0571) : 0.0632 \tCost(-1.0571) : 0.0095 \n",
      "G(-1.0734) : -0.1651 \tG'(-1.0734) : 0.0581 \tCost(-1.0734) : 0.0095 \n",
      "G(-1.0861) : -0.1658 \tG'(-1.0861) : 0.0541 \tCost(-1.0861) : 0.0094 \n",
      "G(-1.0963) : -0.1663 \tG'(-1.0963) : 0.0507 \tCost(-1.0963) : 0.0094 \n",
      "G(-1.1047) : -0.1667 \tG'(-1.1047) : 0.0479 \tCost(-1.1047) : 0.0094 \n",
      "G(-1.1119) : -0.1671 \tG'(-1.1119) : 0.0456 \tCost(-1.1119) : 0.0094 \n",
      "G(-1.118) : -0.1674 \tG'(-1.118) : 0.0435 \tCost(-1.118) : 0.0094 \n",
      "G(-1.1233) : -0.1676 \tG'(-1.1233) : 0.0417 \tCost(-1.1233) : 0.0094 \n",
      "G(-1.128) : -0.1678 \tG'(-1.128) : 0.0401 \tCost(-1.128) : 0.0094 \n",
      "G(-1.1322) : -0.1679 \tG'(-1.1322) : 0.0386 \tCost(-1.1322) : 0.0094 \n",
      "G(-1.1359) : -0.1681 \tG'(-1.1359) : 0.0373 \tCost(-1.1359) : 0.0094 \n",
      "G(-1.1393) : -0.1682 \tG'(-1.1393) : 0.0361 \tCost(-1.1393) : 0.0094 \n",
      "G(-1.1423) : -0.1683 \tG'(-1.1423) : 0.0351 \tCost(-1.1423) : 0.0094 \n",
      "G(-1.1451) : -0.1684 \tG'(-1.1451) : 0.0341 \tCost(-1.1451) : 0.0094 \n",
      "G(-1.1476) : -0.1685 \tG'(-1.1476) : 0.0332 \tCost(-1.1476) : 0.0094 \n",
      "\n",
      "\n",
      "Mostrando resultados para lambda 0.1 \n",
      "\n",
      "G(0.8178) : 0.1859 \tG'(0.8178) : 0.2765 \tCost(0.8178) : 0.0216 \n",
      "G(0.442) : 0.0931 \tG'(0.442) : 0.2246 \tCost(0.442) : 0.0178 \n",
      "G(0.1891) : 0.0386 \tG'(0.1891) : 0.2081 \tCost(0.1891) : 0.0158 \n",
      "G(-0.003) : -0.0006 \tG'(-0.003) : 0.1999 \tCost(-0.003) : 0.0144 \n",
      "G(-0.1547) : -0.0304 \tG'(-0.1547) : 0.1935 \tCost(-0.1547) : 0.0134 \n",
      "G(-0.2763) : -0.0536 \tG'(-0.2763) : 0.1873 \tCost(-0.2763) : 0.0127 \n",
      "G(-0.3749) : -0.0718 \tG'(-0.3749) : 0.1808 \tCost(-0.3749) : 0.0121 \n",
      "G(-0.4557) : -0.0861 \tG'(-0.4557) : 0.1742 \tCost(-0.4557) : 0.0117 \n",
      "G(-0.5224) : -0.0975 \tG'(-0.5224) : 0.1677 \tCost(-0.5224) : 0.0113 \n",
      "G(-0.5782) : -0.1067 \tG'(-0.5782) : 0.1614 \tCost(-0.5782) : 0.0111 \n",
      "G(-0.6254) : -0.1142 \tG'(-0.6254) : 0.1554 \tCost(-0.6254) : 0.0109 \n",
      "G(-0.6656) : -0.1203 \tG'(-0.6656) : 0.1498 \tCost(-0.6656) : 0.0107 \n",
      "G(-0.7002) : -0.1254 \tG'(-0.7002) : 0.1445 \tCost(-0.7002) : 0.0105 \n",
      "G(-0.7303) : -0.1297 \tG'(-0.7303) : 0.1396 \tCost(-0.7303) : 0.0104 \n",
      "G(-0.7567) : -0.1333 \tG'(-0.7567) : 0.1351 \tCost(-0.7567) : 0.0103 \n",
      "G(-0.7801) : -0.1364 \tG'(-0.7801) : 0.1308 \tCost(-0.7801) : 0.0102 \n",
      "G(-0.8008) : -0.1391 \tG'(-0.8008) : 0.1269 \tCost(-0.8008) : 0.0102 \n",
      "G(-0.8194) : -0.1414 \tG'(-0.8194) : 0.1232 \tCost(-0.8194) : 0.0101 \n",
      "G(-0.8361) : -0.1435 \tG'(-0.8361) : 0.1198 \tCost(-0.8361) : 0.01 \n",
      "G(-0.8512) : -0.1453 \tG'(-0.8512) : 0.1166 \tCost(-0.8512) : 0.01 \n",
      "\n",
      "\n",
      "Mostrando resultados para lambda 0.01 \n",
      "\n",
      "G(1.6808) : 0.5523 \tG'(1.6808) : 0.6471 \tCost(1.6808) : 0.0416 \n",
      "G(1.4883) : 0.4401 \tG'(1.4883) : 0.5233 \tCost(1.4883) : 0.0345 \n",
      "G(1.3488) : 0.3724 \tG'(1.3488) : 0.4503 \tCost(1.3488) : 0.0307 \n",
      "G(1.2387) : 0.3255 \tG'(1.2387) : 0.4016 \tCost(1.2387) : 0.0282 \n",
      "G(1.147) : 0.2903 \tG'(1.147) : 0.3666 \tCost(1.147) : 0.0264 \n",
      "G(1.0682) : 0.2625 \tG'(1.0682) : 0.3402 \tCost(1.0682) : 0.0251 \n",
      "G(0.9988) : 0.2396 \tG'(0.9988) : 0.3197 \tCost(0.9988) : 0.024 \n",
      "G(0.9366) : 0.2202 \tG'(0.9366) : 0.3032 \tCost(0.9366) : 0.0231 \n",
      "G(0.88) : 0.2035 \tG'(0.88) : 0.2897 \tCost(0.88) : 0.0224 \n",
      "G(0.828) : 0.1887 \tG'(0.828) : 0.2785 \tCost(0.828) : 0.0217 \n",
      "G(0.7798) : 0.1755 \tG'(0.7798) : 0.2691 \tCost(0.7798) : 0.0212 \n",
      "G(0.7348) : 0.1636 \tG'(0.7348) : 0.2611 \tCost(0.7348) : 0.0207 \n",
      "G(0.6925) : 0.1527 \tG'(0.6925) : 0.2543 \tCost(0.6925) : 0.0202 \n",
      "G(0.6526) : 0.1427 \tG'(0.6526) : 0.2483 \tCost(0.6526) : 0.0198 \n",
      "G(0.6147) : 0.1334 \tG'(0.6147) : 0.2432 \tCost(0.6147) : 0.0194 \n",
      "G(0.5787) : 0.1247 \tG'(0.5787) : 0.2387 \tCost(0.5787) : 0.0191 \n",
      "G(0.5443) : 0.1165 \tG'(0.5443) : 0.2347 \tCost(0.5443) : 0.0187 \n",
      "G(0.5114) : 0.1089 \tG'(0.5114) : 0.2312 \tCost(0.5114) : 0.0184 \n",
      "G(0.4798) : 0.1016 \tG'(0.4798) : 0.228 \tCost(0.4798) : 0.0181 \n",
      "G(0.4494) : 0.0947 \tG'(0.4494) : 0.2252 \tCost(0.4494) : 0.0179 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos para diferentes valores de lambda\n",
    "lambda_values = [1, 0.1, 0.01]\n",
    "hist = []\n",
    "for l in lambda_values:\n",
    "    print(\"Mostrando resultados para lambda {} \\n\".format(l))\n",
    "    min_f = MinFunction(lambda_param=l)\n",
    "    hist.append(min_f.fit())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ahora procedemos a graficar\n",
    "plt.plot(hist[0].keys(), hist[0].values(), color='k', linestyle='dashed', linewidth = 2, markersize=10, label = \"lambda 1\")\n",
    "plt.plot(hist[1].keys(), hist[1].values(), color='g', linestyle='dashed', linewidth = 2, markersize=10,label = \"lambda 0.1\")\n",
    "plt.plot(hist[2].keys(), hist[2].values(), color='r', linestyle='dashed', linewidth = 2, markersize=10,label = \"lambda 0.01\")\n",
    "\n",
    "plt.xlabel('iterationes')\n",
    "plt.ylabel('coste') \n",
    "\n",
    "plt.title('coste para diferentes lambda') \n",
    "plt.legend() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. En clase hemos tratada la regresión ridge ($l_2$-regularizada) y $l_1$-regularizada (lasso). Existe una versión híbrida llamada *elástic net* que usa términos de regularización $l_1$ y $l_2$:\n",
    "\n",
    "$$J_{EL} = \\Vert \\mathbf{y} -\\mathbf{Xw} \\Vert^2 + \\lambda_1 \\Vert \\mathbf{w} \\Vert_1 + \\lambda_2 \\Vert \\mathbf{w} \\Vert^2$$\n",
    "\n",
    "    Si definimos:\n",
    "\n",
    "$$J_{2} = \\Vert \\mathbf{\\tilde{y}} -\\mathbf{\\tilde{X}w} \\Vert^2  + c\\lambda_1 \\Vert \\mathbf{w} \\Vert_1$$\n",
    "\n",
    "donde $c = (1 + \\lambda_2)^{-1/2}$ y \n",
    "\n",
    "$$\n",
    "\\mathbf{\\tilde{X}} = \\begin{pmatrix}\n",
    "\\mathbf{X}\\\\\n",
    "\\sqrt{\\lambda_2}\\mathbf{I}_d\n",
    "\\end{pmatrix}, \\qquad \\mathbf{\\tilde{y}} =  \\begin{pmatrix}\n",
    "\\mathbf{y}\\\\\n",
    "\\mathbf{0}_{d \\times 1}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Muestra que: \n",
    "\n",
    "$$arg \\min_{\\mathbf{w}}J_{EL}(\\textbf{w}) = c(arg \\min_{\\mathbf{w}}J_2(\\mathbf{w})))$$.\n",
    "\n",
    "Esto implica que un problema de *elastic net* puede resolverse como un problema de *lasso*, utilizando datos modificados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTA: EN CASO NO SE VISUALICE LA IMAGEN, ESTA SE ENCUENTRA EN LA CARPETA DE LA CALIFICADA, 'demo.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <br>\n",
    "    <img src=\"./demo.jpg\"/>\n",
    "    <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Explica los siguientes resultados indicando verdadero o falso. Se puntuara si se contesta todas los ítems.\n",
    "\n",
    " * Para la regresión logística, con parámetros optimizados mediante un método de gradiente estocástico, establecer los parámetros en $0$ es una inicialización aceptable.\n",
    "\n",
    " * El uso de la validación cruzada para seleccionar hiperparámetros garantizará que nuestro modelo no se sobreajuste.\n",
    "\n",
    " * Los algoritmos Bagging asignan pesos $w_1 \\dots, w_n$ a un conjunto de $N$ estudiantes débiles. Vuelven a ponderar a los alumnos y los convierten en fuertes. Los algoritmos Boosting extraen $N$ distribuciones de muestra (generalmente con reemplazo) de un conjunto de datos original para que los alumnos se entrenen.\n",
    "\n",
    " * Un árbol de decisión binario de profundidad infinita siempre puede alcanzar el $100\\%$ de exactitud en el entrenamiento, siempre que ningún punto esté mal etiquetado en el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Verdadero, solo para el caso de una regresión logistica, incluso si los pesos se ponen en 0, lo logra una convergencia mediante SGD. Sin embargo esto no es cierto en redes neuronales, pues no permite realizar el proceso de backpropagation.\n",
    "\n",
    "b) Falso, si bien muchas veces es usado como técnica para combatir el sobreajuste, no funcionará bien con datos externos si los datos que tiene no son representativos de los datos que intentará predecir.\n",
    "\n",
    "c) Falso, las definiciones estan intercambiadas. Boosting trata de añadir nuevos modelos que funcionan bien donde los modelos anteriores carecen.\n",
    "\n",
    "d) Verdad, esto es cierto para una profundidad infinita, pues cada división binaria interna dentro del árbol por cada nivel se ajusta perfectamente a todos los datos de entrenamiento, sin embargo no se logra una generalización para los datos de prueba, debido a que se esta sobreajustando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Se podría perforar un pozo de petróleo en la granja del profesor Neapolitan en Texas. Con base en lo que ha sucedido en granjas similares, juzgamos que la probabilidad de que haya petróleo presente es de $0.5$, la probabilidad de que solo esté presente gas natural es de $0.2$ y la probabilidad de que ninguno de los dos esté presente es de $0.3$. Si hay petróleo presente, una prueba geológica dará un resultado positivo con probabilidad de $0.9$,  si solo hay gas natural, dará un resultado positivo con probabilidad $0.3$  y si ninguno está presente, la prueba será positiva con probabilidad $0.1$. Supongamos que la prueba resulta positiva. Utilice el teorema de Bayes para calcular la probabilidad de que haya petróleo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pet: hay petroleo 1 , no hay petroleo 0\n",
    "Gas: hay gas 1, no hay gas 0\n",
    "Res: positivo 1, negativo 0\n",
    "\n",
    "Datos:\n",
    "    P(Pet=1) = 0.5  \n",
    "    P(Gas=1) = 0.2\n",
    "    P(Pet=0, Gas=0) = P(nada) = 0.3\n",
    "    P(Res=1 | Pet=1) = 0.9\n",
    "    P(Res=1 | Gas=1) = 0.3\n",
    "    P(Res=1 | Pet=0, Gas=0) = P(Res=1 | nada) = 0.1\n",
    "    \n",
    "Calcular P(Pet=1 | Res =1)\n",
    "\n",
    "Usando el teorema de Bayes:\n",
    "    𝑃(Pet=1|Res=1) = 𝑃(Res=1|Pet=1) * 𝑃(Pet=1) / 𝑃(Res=1) \n",
    "    \n",
    "De los datos tenemos:\n",
    "    𝑃(Res=1|Pet=1) = 0.9\n",
    "    𝑃(Pet=1) = 0.5\n",
    "    \n",
    "    𝑃(Pet=1|Res=1) = 0.9 * 0.5 / 𝑃(Res=1)   .... (*)\n",
    "\n",
    "Ahora hallaremos 𝑃(Res=1):\n",
    "    𝑃(Res=1) = 𝑃(Res=1|Pet=1)*P(Pet=1) + 𝑃(Res=1|gas=1)*P(gas) + P(Res=1 | nada) 𝑃(nada)  = 0.9*0.5 + 0.3*0.2 + 0.1*0.3 =   ...(**)\n",
    "    \n",
    "\n",
    "Finalmente en (*):\n",
    "    𝑃(Pet=1|Res=1) = 0.9 * 0.5 / \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 . Se te proporciona un modelo de Bayes, que se muestra a continuación, con la etiqueta $Y$ y las características $X_1$ y $X_2$. Las probabilidades condicionales del modelo están parametrizadas por $p_1$, $p_2$ y $q$.\n",
    "\n",
    "![](NaiveBayes.png)\n",
    "\n",
    "Ten en cuenta que algunos de los parámetros son compartidos (por ejemplo, $P(X_1 = 0|Y = 0)=P(X_1 = 1|Y = 1) = p_1$).\n",
    "\n",
    "\n",
    "Dado un nuevo punto de dato con $X_1 = 1$ y $X_2 = 1$, ¿cuál es la probabilidad de que este punto tenga la etiqueta $Y = 1$? Expresa tu respuesta en términos de los parámetros $p_1$, $p_2$ y $q$ (es posible que no los necesite todos). Es decir debes calcular : $P(Y= 1| X_1= 1,X_2= 1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <br>\n",
    "    <img src=\"https://economipedia.com/wp-content/uploads/Teorema-de-Bayes-1.png\"/>\n",
    "    <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "𝑃(𝑌=1|𝑋1=1,𝑋2=1) = 𝑃(𝑌=1|𝑋1=1)𝑃(𝑌=1|𝑋2=1)  .... (*)\n",
    "\n",
    "-> usando el teorema de Bayes\n",
    "\n",
    "a)\n",
    "\n",
    "𝑃(𝑌=1|𝑋1=1) = 𝑃(𝑋1=1|𝑌=1)* 𝑃(𝑌=1) / 𝑃(𝑋1=1) = p1 * q / 𝑃(𝑋1=1)\n",
    "-> 𝑃(𝑋1=1) = ((1-p1)*(1-q) + p1*q)\n",
    "\n",
    "finalmente ->  𝑃(𝑌=1|𝑋1=1) = p1 * q / ((1-p1)*(1-q) + p1*q)\n",
    "\n",
    "b)\n",
    "\n",
    "𝑃(𝑌=1|𝑋2=1) = 𝑃(𝑋2=1|𝑌=1)* 𝑃(𝑌=1) / 𝑃(𝑋2=1) = p2 * q / 𝑃(𝑋2=1)\n",
    "-> 𝑃(𝑋2=1) = ((1-p2)*(1-q) + p2*q)\n",
    "finalmente ->  𝑃(𝑌=1|𝑋2=1) = p2 * q / ((1-p2)*(1-q) + p2*q)\n",
    "\n",
    "uniendo a y b en (*) tenemos:\n",
    "   𝑃(𝑌=1|𝑋1=1,𝑋2=1) = 𝑃(𝑌=1|𝑋1=1)𝑃(𝑌=1|𝑋2=1) = p1 * q * p2 * q  = p1*p2*(q^2) / (((1-p1)*(1-q) + p1*q) * ((1-p2)*(1-q) + p2*q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Explica los siguientes resultados indicando verdadero o falso. Se puntuara si se contesta todas los ítems.\n",
    "\n",
    "  * La acción realizada por un agente racional siempre será una función determinista de las percepciones actuales del agente.\n",
    "\n",
    " * Una ruta de solución óptima para un problema de búsqueda con costos positivos nunca tendrá estados repetidos.\n",
    "\n",
    " * Si dos heurísticas de búsqueda $h_1(s)$ y $h_2(s)$ tienen el mismo valor promedio, la heurística $h_3(s) = \\max (h_1(s), h_2(s))$ podría dar una mejor eficiencia $A^*$ que $h_1$ o $h_2$.\n",
    "\n",
    " * Para cualquier conjunto de atributos, y cualquier conjunto de entrenamiento generado por una función determinista para esos atributos, existe un árbol de decisiones que es consistente con ese conjunto de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Verdadero, un agente racional debe \"hacer lo correcto\", en función de lo que pueda percibir actualmente y las acciones que puede realizar. La acción correcta es la uno que hará que el agente tenga más éxito, dicha acción se basa en reglas determinísticas determinada por una función determística..\n",
    "\n",
    "b) Verdadero, en cualquier ruta de solución con estados que se repiten n veces, eliminar un ciclo produce una ruta cuya solución siempre tendra un costo mucho menor. \n",
    "c) Verdadero, si tienen el mismo valor promedio entonces existe un g(s) = 1/2 h1(s) + 1/2 h2(s). Sea h^∗(s) la verdadera distancia desde s. Sabemos que h1(s)≤h^∗(s) y h2(s)≤h ∗ (s), entonces g(s) = 1/2 h1(s) + 1/2 h2(s) ≤ 1/2 h^∗(s) + 1/2 h^∗(s ) = h^∗(s)\n",
    "d) Verdadero, debido a que los atributos de ese conjunto de entrenamiento se puede reducir en condiciones binarias que pueden ser modelado por un árbol de decisión de determinado nivel o altura H. Para un árbol de profundidad infinita, siempre se convergerá a un modelamiento de dichos atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 . Usaremos el conjunto de datos [*Breast Cancer Wisconsin (Diagnostic)*](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/version/2), llamado `data.csv`\n",
    "\n",
    " * ¿Cuántas observaciones (filas) hay en el conjunto de datos?\n",
    " * Asigna a una lista de nombre `feature_columns` todas las columnas del conjunto de datos menos el `id` de cada observación y la clase `diagnosis` que es la que buscaremos predecir.\n",
    " * Crea una nueva columna `'target'` que tenga un valor numérico de `+1` en las muestras positivas (cuando el diagnóstico sea maligno) y `-1` en las muestra negativas (diagnóstico benigno).\n",
    " * Empleando `sklearn.model_selection.train_test_split` separa el conjunto de datos en un 90% para entrenamiento y validación (`X_trainval`, `y_trainval`), y 10% para pruebas (`X_test`, `y_test`).\n",
    "\n",
    "   Luego separa (`X_trainval`, `y_trainval`) en un 80% para entrenamiento (`X_train`, `y_train`) y 20% para validación (`X_val`, `y_val`).\n",
    "   \n",
    "* Empleando `sklearn.preprocessing.StandardScaler` se ha normalizado en un arreglo `X_trainval_scaled` el conjunto de entrenamiento y validación. Usa `sklearn.decomposition.PCA` para calcular los vectores de carga **`pca_loadings`** y el puntaje **`pca_scores`** de cada observación en el espacio de los componentes principales.\n",
    "\n",
    "* Crea una instancia de la clase `sklearn.linear_model.LogisticRegression` y ajusta un modelo con el conjunto de **entrenamiento**\n",
    "\n",
    "* Usa el modelo para predecir la probabilidad de que cada una de las observaciones de conjunto de **validación** corresponda a la clase positiva (diagnóstico maligno)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "datos = pd.read_csv(\"data.csv\")\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "datos.info()\n",
    "\n",
    "# vemos en la parte inferior que tenemos 569 filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0       1        17.99         10.38          122.80     1001.0   \n",
       "1       1        20.57         17.77          132.90     1326.0   \n",
       "2       1        19.69         21.25          130.00     1203.0   \n",
       "3       1        11.42         20.38           77.58      386.1   \n",
       "4       1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modificamos los targets\n",
    "\n",
    "datos.diagnosis.replace('B', -1,inplace=True)\n",
    "datos.diagnosis.replace('M', 1,inplace=True)\n",
    "\n",
    "# eliminamos la columna de id\n",
    "datos = datos.drop([\"id\", \"Unnamed: 32\"], axis=1)\n",
    "\n",
    "# renombramos la columna diagnosis por target\n",
    "datos.rename(columns={'diagnosis':'target'}, \n",
    "                 inplace=True)\n",
    "\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.11890</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.08902</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.08758</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.17300</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.07678</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fractal_dimension_worst  radius_mean  texture_mean  perimeter_mean  \\\n",
       "0                  0.11890        17.99         10.38          122.80   \n",
       "1                  0.08902        20.57         17.77          132.90   \n",
       "2                  0.08758        19.69         21.25          130.00   \n",
       "3                  0.17300        11.42         20.38           77.58   \n",
       "4                  0.07678        20.29         14.34          135.10   \n",
       "\n",
       "   area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "0     1001.0          0.11840           0.27760          0.3001   \n",
       "1     1326.0          0.08474           0.07864          0.0869   \n",
       "2     1203.0          0.10960           0.15990          0.1974   \n",
       "3      386.1          0.14250           0.28390          0.2414   \n",
       "4     1297.0          0.10030           0.13280          0.1980   \n",
       "\n",
       "   concave points_mean  symmetry_mean  ...  radius_worst  texture_worst  \\\n",
       "0              0.14710         0.2419  ...         25.38          17.33   \n",
       "1              0.07017         0.1812  ...         24.99          23.41   \n",
       "2              0.12790         0.2069  ...         23.57          25.53   \n",
       "3              0.10520         0.2597  ...         14.91          26.50   \n",
       "4              0.10430         0.1809  ...         22.54          16.67   \n",
       "\n",
       "   perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0           184.60      2019.0            0.1622             0.6656   \n",
       "1           158.80      1956.0            0.1238             0.1866   \n",
       "2           152.50      1709.0            0.1444             0.4245   \n",
       "3            98.87       567.7            0.2098             0.8663   \n",
       "4           152.20      1575.0            0.1374             0.2050   \n",
       "\n",
       "   concavity_worst  concave points_worst  symmetry_worst  target  \n",
       "0           0.7119                0.2654          0.4601       1  \n",
       "1           0.2416                0.1860          0.2750       1  \n",
       "2           0.4504                0.2430          0.3613       1  \n",
       "3           0.6869                0.2575          0.6638       1  \n",
       "4           0.4000                0.1625          0.2364       1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cambiamos el orden de las columnas\n",
    "cols = datos.columns.tolist()\n",
    "\n",
    "cols[0], cols[30] = cols[30], cols[0]\n",
    "\n",
    "datos = datos[cols]\n",
    "\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fractal_dimension_worst', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst']\n"
     ]
    }
   ],
   "source": [
    "# ahora creamos la lista feature_columns\n",
    "feature_columns = datos.columns.tolist()[0:-1]\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (409, 30)  y_train shape(409,)\n",
      "\n",
      "X_val shape: (103, 30)\t y_val shape(103,)\n",
      "\n",
      "X_test shape: (57, 30)\t y_test shape(57,)\n"
     ]
    }
   ],
   "source": [
    "# división de los datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = datos.drop(\"target\", axis=1).values\n",
    "y = datos.target.values\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size = 0.1, random_state=0)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size = 0.2, random_state=0)\n",
    "\n",
    "print(\"X_train shape: {}  y_train shape{}\".format(X_train.shape, y_train.shape))\n",
    "print(\"\\nX_val shape: {}\\t y_val shape{}\".format(X_val.shape, y_val.shape))\n",
    "print(\"\\nX_test shape: {}\\t y_test shape{}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos e instanciamos el modelo de regresión\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# para el entrenamiento usaremos la mitad de las componentes totales de las características\n",
    "pca = PCA(n_components=15)\n",
    "\n",
    "logReg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "model = make_pipeline(StandardScaler(), pca, logReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('pca', PCA(n_components=15)),\n",
       "                ('logisticregression', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nota: \n",
    "No estamos usando el conjunto de validación porque no usamos búsqueda de hiperparámetros (con grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntaje en el conjunto de entrenamiento: 0.987775\n",
      "Puntaje en el conjunto de validación: 0.990291\n",
      "Puntaje en el conjunto de prueba: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# mostramos los puntajes alcanzados en el conjunto de entrenamiento, validación y prueba\n",
    "print(\"Puntaje en el conjunto de entrenamiento: %f\" % model.score(X_train, y_train))\n",
    "print(\"Puntaje en el conjunto de validación: %f\" % model.score(X_val, y_val))\n",
    "print(\"Puntaje en el conjunto de prueba: %f\" % model.score(X_test, y_test))\n",
    "\n",
    "# observamos que el modelo NO sufre de sobreajuste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  [[6.788e-02 1.321e+01 2.525e+01 8.410e+01 5.379e+02 8.791e-02 5.205e-02\n",
      "  2.772e-02 2.068e-02 1.619e-01 5.584e-02 2.084e-01 1.350e+00 1.314e+00\n",
      "  1.758e+01 5.768e-03 8.082e-03 1.510e-02 6.451e-03 1.347e-02 1.828e-03\n",
      "  1.435e+01 3.423e+01 9.129e+01 6.329e+02 1.289e-01 1.063e-01 1.390e-01\n",
      "  6.005e-02 2.444e-01]]\n",
      "target:  [-1]\n",
      "predicción:  [-1]\n"
     ]
    }
   ],
   "source": [
    "# hacemos una predicción\n",
    "\n",
    "print(\"input: \", X_test[1:2])\n",
    "print(\"target: \", y_test[1:2])\n",
    "print(\"predicción: \", model.predict(X_test[1:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ahora nuestro modelo esta listo para predecir alguna de las siguientes clases\n",
    "model.classes_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     benigno       0.99      1.00      0.99        67\n",
      "     maligno       1.00      0.97      0.99        36\n",
      "\n",
      "    accuracy                           0.99       103\n",
      "   macro avg       0.99      0.99      0.99       103\n",
      "weighted avg       0.99      0.99      0.99       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = y_val\n",
    "y_pred = model.predict(X_val)\n",
    "target_names = [\"benigno\", \"maligno\"]  # 1 para maligno y -1 para benigno\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "# mirando el siguiente cuadro concluimos, usando la definición de precision (!= accuracy), de que una observación corresponda\n",
    "# a la clase positiva (maligno) viene dada por 1.00 TP/TP+FP\n",
    "\n",
    "# nota: ESTOS RESULTADOS SON EN BASE AL CONJUNTO DE VALIDACIÓN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puntos extras: Calcula las predicciones en el conjunto de validación con un umbral de probabilidad `> 0.7`, indicando a continuación la matriz de confusión, la exactitud, precisión, exhaustividad de las predicciones. Se provee la función `print_binary_confusion_matrix` para mostrar la matriz de confusión. \n",
    "\n",
    "```\n",
    "from sklearn import metrics\n",
    "\n",
    "def print_binary_confusion_matrix(matrix):\n",
    "    TN = matrix[0,0]\n",
    "    FN = matrix[1,0]\n",
    "    FP = matrix[0,1]\n",
    "    TP = matrix[1,1]\n",
    "\n",
    "    print ('              +-----------------+')\n",
    "    print ('              |   Predicción    |')\n",
    "    print ('              +-----------------+')\n",
    "    print ('              |    +   |    -   |')\n",
    "    print ('+-------+-----+--------+--------+')\n",
    "    print ('| Valor |  +  |  {:5d} |  {:5d} |'.format(TP, FN) )\n",
    "    print ('| real  +-----+--------+--------+')\n",
    "    print ('|       |  -  |  {:5d} |  {:5d} |'.format(FP, TN) )\n",
    "    print ('+-------+-----+--------+--------+')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def print_binary_confusion_matrix(matrix):\n",
    "    TN = matrix[0,0]\n",
    "    FN = matrix[1,0]\n",
    "    FP = matrix[0,1]\n",
    "    TP = matrix[1,1]\n",
    "\n",
    "    print ('              +-----------------+')\n",
    "    print ('              |   Predicción    |')\n",
    "    print ('              +-----------------+')\n",
    "    print ('              |    +   |    -   |')\n",
    "    print ('+-------+-----+--------+--------+')\n",
    "    print ('| Valor |  +  |  {:5d} |  {:5d} |'.format(TP, FN) )\n",
    "    print ('| real  +-----+--------+--------+')\n",
    "    print ('|       |  -  |  {:5d} |  {:5d} |'.format(FP, TN) )\n",
    "    print ('+-------+-----+--------+--------+')\n",
    "    \n",
    "\n",
    "y_true = y_val\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "matrix = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              +-----------------+\n",
      "              |   Predicción    |\n",
      "              +-----------------+\n",
      "              |    +   |    -   |\n",
      "+-------+-----+--------+--------+\n",
      "| Valor |  +  |     35 |      1 |\n",
      "| real  +-----+--------+--------+\n",
      "|       |  -  |      0 |     67 |\n",
      "+-------+-----+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "print_binary_confusion_matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
